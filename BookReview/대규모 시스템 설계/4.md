처리율 제한 장치의 설계
=

대형 IT기업들은 어떤 형태로든 처리율 제한 장치를 가지고있다.

ex) 트위터는 3시간 동안 300개의 트윗만 올릴 수 있다.
구글 독스는 사용자가 분당 300회의 read요청만 허용한다.

비정상적인 추가 요청을 사전에 막아 리소스소모를 막을 수 있고, 외부 api를 비용을 지불하고 사용 중이라면 비용 절감 효과와 트래픽을 제어할 수 있다.

## 처리율 제한 장치는 어디에 둘 것인가?

클라이언트 쪽은 위변조가 쉽기때문에 서버 쪽에 두는 것이 옳다.

그렇다면 **서버 내부에 둘 것인가** **서버 바깥 api게이트웨이를 도입**할것인가?

api 게이트웨이는 서버 외부에 존재하고 클라이언트 요청을 먼저 받아서 처리율 제한을 걸어 api에 요청을 전달한다.

보통 상용 게이트웨이서버가 있어서 모든 유지보수를 위탁해서 관리하는 서비스이다.

서버 내부에 두어야한다면 기업의 역량에 따라 달라질 수 있다.

## 처리율 제한 알고리즘

1. 토큰 버킷 알고리즘

    토큰을 담을 수 잇는 바구니를 생각해보자.

    이 바구니에는 정해진 양의 토큰을 담을 수 있다.

    토큰 공급기는 지정된 속도로 토큰을 공급한다.

    토큰 공급기가 초당 2개의 토큰을 공급하고 토큰 버킷의 용량은 4개인 식으로 구성할 수 있다.

    토큰 버킷이 꽉 차있다면 요청을 4개를 처리할 수 있다.

    하지만 토큰이 없다면 해당 요청은 버려진다.

    버킷의 크기, 토큰 공급의 주기를 결정해 처리율을 결정한다. (이 두가지 변수를 튜닝하는 것이 까다롭긴하다.)

    토큰이 충분하기만하다면 짧은 시간에 집중되는 트래픽도 처리가 가능하다.

    이 알고리즘은 처리율이 고정되어있지 않다. 시간을 구간별로 나누면 어떤 구간은 처리율이 낮고 어떤 구간은 처리율이 높다. 토큰이 있기만하면 즉각적인 처리를 하기때문이다.

2. 누출 버킷 알고리즘

    이 알고리즘은 위와 다르게 처리율이 고정돼있다.

    버킷은 큐로 구현하고 큐의 사이즈가 넘치면 요청은 버려진다.

    1번 알고리즘과 다르게 큐에서 꺼내 작업을 처리하는 속도가 일정하게 정해져있다.(들어오는 순서로 즉각적으로 큐에서 꺼내 처리하지않는다는 의미)

    단시간에 몰리는 서비스에는 적합하지않다. (유연성이 떨어짐)

3. 고정 윈도 카운터 알고리즘

    1초마다 구간을 나누어 해당 구간에 처리할 수 있는 최대 요청을 정해놓는다.

    1초에 3개를 처리하는 처리율이라면 4개의 요청이 1초에 들어오면 1개의 요청은 버려진다.

    이 알고리즘은 한 가지 문제점이 있는데, 1.999초와 2.0001초 사이에 요청이 몰리면 총 6개의 요청이 1초안에 몰리게된다.

    0~1초 1~2초 사이에는 3개의 요청으로 벗어나지않지만 위 구간에서는 처리가 초당 6건으로 벗어나게된다.

4. 이동 윈도 로깅 카운터 알고리즘

    경계 구간에 요청이 몰리는 것을 해결한 알고리즘이다.

    알고리즘 단어에서 알 수 있듯이 로그기록을 이용해 처리한다.

    요청 시간을 로그로 기록하는데 분당 2개의 요청을 처리하는 알고리즘으로 설계했다면 1분 안에 3개의 요청이 온다면 마지막에 들어온 요청은 로그엔 기록되지만 요청이 처리되지않는다.

    다음 1분에 요청이 들어오면 이전 요청은 만료됐기때문에 지워버리고 2개의 추가 요청을 처리한다.

    특정 구간에 몰리더라도 로그엔 기록하고 1분 단위로 처리하기때문에 3번 알고리즘의 문제를 해결한다.

5. 이동 윈도 카운터 알고리즘

    3,4번 알고리즘을 결합한 알고리즘이다.

    현재 1분간 요청수 + 직전 1분간의 요청 수 x 이동 윈도와 직전 1분이 겹치는 비율 을 계산해서 처리율을 계산하고 새로운 요청을 처리할 지 말지를 결정한다.

    특정구간에 요청이 몰리더라도 비율을 계산하기때문에 꽤 정확히 처리율에 맞출 수 있다. 40억개의 요청 중 버려진 요청이 0.003%라고 한다.

## 상세설계

클라이언트가 요청을 보내면 게이트웨이에 먼저 도착해 처리율을 계산해야한다.

위에서 보듯이 처리가 가능한지 불가능한지를 게이트웨어가 정보를 가지고있어야하는데 이때 레디스를 이용한다.

카운터값이 처리율을 넘지않으면 카운터를 올리고, 처리율을 넘었다면 버리거나 **메세지 큐**에 보관한다.

## 경쟁조건

데이터베이스를 이용하는 모든 서버가 겪는 문제같다.

답을 읽기전에 단순하게 생각해봤다.

데이터베이스는 경쟁이 붙는다면 락을 걸어 다른 스레드가 참여하지 못하게한다.

성능상의 문제로 읽기엔 락을 걸지않고 쓰기시에만 락을 걸지않으면 되지않을까?(레디스에 카운터 증가)

하지만 성능상의 문제가 뒤따를 것이다.

책에서도 정확히 지적하는 문제다.

책에서 제시하는 해결책은 정렬 집합을 이용하는 방법을 제시했다.

## Redis Sort Set

레디스의 정렬집합은 하나의 key가 여러개의 value/score를 갖는다.

선착순 이벤트를 예시로들어보면, value에는 회원 고유 ID score는 이벤트 요청 시각이다.

중요한 것은 score를 기준으로 정렬된다는 것이다.

이렇게되면 순차적으로 DB에 쿼리를 날릴 수 있다.

동시에 들어왔다고 해도 그 동시성은 지키면서 DB의 경쟁조건을 완화시킬 수 있게된다.

## 동기화 이슈

기본적으로 웹 계층은 무상태이다.

서버는 상태를 기억하지 않는다는 것이다.

만약 처리율 제한장치가 여러 서버로 둔다면 문제가 발생할 수 있다.

1번 유저가 1번 서버에 접근해 분당 5건의 요청을 이미 처리했다. 하지만 1번 유저가 2번 서버에서 같은 기간안에 3건의 요청을 추가한다면 2번 서버는 1번 유저에대해 알지 못하기때문에 요청을 수행하게될텐데 이는 처리율을 넘어서는 요청이다.

해결책은 두 처리율 제한장치가 하나의 중앙집중형 DB를 사용하는 것이다.